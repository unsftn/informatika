---
layout: page
title: Projects
permalink: /projects/
---

### INCOMING: Interdisciplinary Curricula in Computing to Meet Labor Market Needs

[INCOMING](http://tempus-incoming.eu/) is a 3-year project (2012-2015) 
funded by the TEMPUS IV programme of the European Union (project No. 
530155-TEMPUS-1-2012-1-EE-TEMPUS-JPCR). It is a Joint Project / Curricular Reform 
(JPCR) project with the objective to initiate capacity building for 
interdisciplinary studies at universities in Serbia, to be offered both in 
English and in Serbian, at all three levels of study (BSc, MSc, PhD), and in 
at least one of the following three modes of study: face-to-face mode, 
distance learning, and blended mode. To do that, the project will develop, 
accredit, implement and evaluate several interdisciplinary study programmes, 
at four different universities in Serbia (see the page 'About the project' 
for details). By developing and implementing these programmes, the project 
intends to enhance employment opportunities for graduates of the new 
programmes, targeting specifically Serbian labor market needs in 
interdisciplinary computing.

### ENGAGE: An Infrastructure for Open, Linked Governmental Data Provision towards Research Communities and Citizens

The main goal of [ENGAGE](http://www.engage-project.eu/) project is the 
development and use of a data infrastructure, incorporating distributed and 
diverse public sector information (PSI) resources, capable of supporting 
scientific collaboration and research, particularly for the Social Science 
and Humanities (SSH) scientific communities, while also empowering the 
deployment of open governmental data towards citizens.The ENGAGE 
e-infrastructure is envisaged to promote a highly synergetic approach to 
governance research, by providing the ground for experimentation to actors 
from both ICT and non-ICT related disciplines and scientific communities, as 
well as by ensuring that the scientific outcomes are made accessible to the 
citizens, so that they can monitor public service delivery and influence the 
decision making process.

Simply put, ENGAGE is a door for researchers that leads them to the world of 
Open Government Data. By using the ENGAGE platform, researchers and citizens 
will be able to submit, acquire, search and visualize diverse, distributed 
and derived Public sector datasets from all the countries of the European 
Union.

ENGAGE is a combination of CP-CSA project funded under the European 
Commission FP7 Programme.

### KEYSTONE: Semantic Keyword-based Search on Structured Data Sources

[KEYSTONE](http://www.keystone-cost.eu/) is a 
[COST Action](http://www.cost.eu/) IC1302 and the main objective of the 
Action is **to launch and establish a cooperative network** of researchers, 
practitioners, and application domain specialists working in fields related 
to semantic data management, the Semantic Web, information retrieval, 
artificial intelligence, machine learning and natural language processing, 
that coordinates collaboration among them **to enable research activity and 
technology transfer in the area of keyword-based search over structured data 
sources**. The coordination effort will promote the development of a new 
revolutionary paradigm that provides users with keyword-based search 
capabilities for structured data sources as they currently do with 
documents. Furthermore, it will exploit the structured nature of data 
sources in defining complex query execution plans by combining partial 
contributions from different sources.

### REVLAB: Renewable Energy Virtual Laboratory

The [REVLAB](http://www.revlab.uns.ac.rs/) project between the University of 
Novi Sad, Faculty of Technical Sciences and the University of Szeged, 
Department of Technical Informatics will start a cross-border research 
cooperation in the field of renewable energy technology which will result in 
the first-of-a-kind high-power renewable energy laboratory that is 
completely safe, scalable and accessible anytime from anywhere in the world.

The projects positive influence on local scientific community is twofold: 
first, the development of the laboratory is a significant technical 
undertaking which will strengthen the participating institutions engineering 
and innovation capacity, and second, once completed the laboratory will 
increase their capacity for research and knowledge transfer.
REVLAB project will create a vibrant community that will use the project 
infrastructure to share the knowledge and experience, solve hard technical 
problems and raise the awareness about the sustainability and green-energy 
issues. By increasing cross-border dialogue between scientific institutions, 
authorities and decision makers, the REVLAB project will have a lasting 
impact on regional renewable energy policy, as well as innovation capacity 
of the regional universities, industry and SMEs.

The key objective of the REVLAB project is the development of 
infrastructural and equipment capacities for research and knowledge transfer 
in the field of renewable energy. REVLAB is a unique virtual laboratory 
based on the stateof the art real-time hardware and software, that will 
enable, for the first time, the researchers and engineers of two 
institutions to access laboratory premises from a distance, to work together 
more closely and more effectively, to perform experiments safely and to develop 
solutions which are the most appropriate for the regions needs.
The specific objectives are:

* to jointly develop the virtual laboratory based on real time emulator 
hardware and software technology;

* to develop web portal and necessary communication and server 
infrastructure to enable constant and online access to the laboratory and 
distant experiments;

* to develop applications for energy efficiency improvement in the field of 
renewable energy sources, such as wind energy and photovoltaic;

* to make the latest achievements in the field of renewable energy 
technology available globally over the Internet by establishing virtual 
laboratory as a new method for knowledge transfer between scientific 
institutions and economy actors, thus directly enhancing the innovative 
capacity of the industry and SMEs in renewable energy sector.

### Semantic-based Document and Workflow Management

Modern organizations aim to enhance the efficiency of business processes, 
to improve the quality of their services and to reduce operational costs, 
and in order to accomplish that goal they are turning more and more to 
document-centric information systems. There is a vast number of document 
management systems and related business process management systems available. 
One of the major obstacles in implementing document-centric information 
systems is a lack of domain specific services (customized retrieval and 
browsing of documents, life-cycle management, security constraints, etc.), 
that requires complicated customization.  Also, the gap between frequently 
changing legislations and regulations on one side, and implemented workflows 
on the other side, is causing difficulties in enforcing regulatory compliance 
of information systems.  Furthermore, significant number of business processes 
is distributed (while current systems tend to manage documents and workflows 
in a centralized manner), and different documents and associated metadata 
representations often causes difficulties for system integration. The aim of 
this project is to investigate the opportunities and benefits of applying 
semantic web technologies to document management and business process 
management in an attempt to address those issues.

### Legal Informatics

We engage in research on the application of computer science and information 
technology in the field of law and develop legal information and software 
systems.

In particular, we are interested in legal document and business process 
management (in legislative, judicial and executive branches of the government 
and legal offices), formal representation of legal knowledge (legal norms and 
legal facts) and legal reasoning. Our long term goal is to close the gap 
between legal documents and legal knowledge. We also promote open legal 
standards and open access to legal information.

Our past and current projects include legal document and business process 
management solutions, legal information retrieval and browsing systems and 
text and data mining in the legal domain.

### MDE Tools for Participative Development of Enterprise Applications

[Kroki](http://www.kroki-mde.net/) (fr. croquis – sketch) is an open-source 
tool for participatory development of business applications based on 
executable mockups. Kroki is being developed in order to foster development 
agility, better understanding of end user needs, and better communication 
among team members with different specialties. The mockups are used not only 
for requirements elicitation but during design and implementation as well, 
because they are later supplied with implementation details through a set 
of views that support participation of developers with different specialties. 
Since Kroki provides immediate execution of the application being sketched, 
it can significantly contribute to decreasing the communication gap between 
development team and end-users.

Mockup creation and execution is based on our 
[EUIS DSL](http://www.doiserbia.nb.rs/img/doi/1820-0214/2011/1820-02141100010P.pdf) 
for specifying user interfaces (UI) of business applications at a high-level 
of abstraction. Unlike most other solutions where only the UI skeleton is 
executable, Kroki’s executable mockups can be tested through all three 
application tiers (the user interface, the business logic, and the database).

Watch a demo at [YouTube](http://youtu.be/r2eQrl11bzA).

### Tools for Domain-Specific Language Engineering

A set of FLOSS tools whose aim is to help in the creation and maintenance of 
textual Domain-Specific Languages. Currently two tools are developed and used 
in both academic and enterprise setups:

* [Arpeggio](https://github.com/igordejanovic/arpeggio) - is a PEG parser 
with full backtracking and memoization (aka packrat) written in Python 
programming language. Arpeggio works as a grammar interpreter. There is no 
code generation. The grammar can be specified in multiple ways: using python 
statements, using PEG notation (there are currently two variants).

* [textX](https://github.com/igordejanovic/textX) - is a high-level library 
for DSL engineering built on top of Arpeggio parser and inspired by Xtext 
tool. From a grammar description textX builds a meta-model and a parser for 
the new language. Language utterances are parsed and automatically 
transformed to a model which corresponds to the automatically deduced 
meta-model. The model can be further transformed, interpreted or a program 
code can be generated out of it.

Language Workbench called [Textile](https://github.com/igordejanovic/Textile) 
is in conception phase. It it envisioned as an IDE built on top of Arpeggio 
and textX that will enable easy DSL specification and evolution.

### Platform-independent Code Generation for Controllers (Typhoon HIL)

Project description

### CRIS UNS: Current Research Information System at University of Novi Sad

CRIS UNS system is under development since the year 2008 within the project 
[Development of Software Infrastructure for Research Domain of the University 
of Novi Sad (DOSIRD UNS)](http://dosird.uns.ac.rs/). It has been implemented 
with an intention to fulfill all specific requirements prescribed by rule 
books of the University of Novi Sad, Provincial Secretariat for Science and 
Technological Development of Autonomous Province of Vojvodina, and Ministry 
of Education, Science and Technological Development of Republic of Serbia. 
In addition, the substantial requirement to be fulfilled by the system CRIS 
UNS is its interoperability with systems possessing large databases of 
scientific research results, thus improving the visibility of the scientific 
results achieved by researchers from University of Novi Sad and therefore 
raising the rating of the University. 

Informational requirements imposed to this system are:

* Access to the application via an arbitrary modern web browser.

* Researchers entering their references by themselves without the need to 
be at home on any standard for references describing.

* Interoperability of our system with diverse systems containing scientific 
content such as CRIS systems, institutional repositories, library information 
systems, digital repositories, etc.

* Capability to search the database containing scientific results.

* Capability to perform evaluation of scientific research results following 
the rule book(s) prescribed by the Ministry of Education, Science and 
Technological Development of Republic of Serbia.

* Reporting for the faculties, University, Provincial Secretariat for Science 
and Technological Development of Autonomous Province of Vojvodina and Ministry 
of Education, Science and Technological Development of Republic of Serbia.

### Automated summarization and sentiment mining in Serbian language

Monitoring public opinions has its use in vast number of domains. For example, 
consumers tend to decide on purchasing a product based on the recommendations 
and advice from other users. It is in the interest of manufacturers to keep 
track of public opinions in order to improve user satisfaction. Political 
parties and public figures have a special interest in the way they are 
portrayed in the media.

Internet is an immense, valuable source of public opinions which can be 
obtained easily and for the low cost through news sites, social media, blog 
posts, review websites, on-line discussions, etc. However, the vast amount 
of opinionated text being produced every day makes manual (human) processing 
impossible, thus revealing the need for their automated retrieval and 
understanding.

Our goal in this project is to develop methods and tools for automated 
processing of texts in Serbian language. Serbian language poses a special 
challenge since text mining and natural language processing tools are very 
scarce and lacking in performance in comparison to well-known languages e.g., 
English. The project encompasses many aspects of text mining and natural 
language processing, such as: text classification, summarization, topic 
mining, subjectivity detection and sentiment mining.

### Healthcare Text Mining

Recent advances in the availability of electronic health records (EHRs) 
provide an opportunity to improve the quality of clinical care and to 
support medical research. While key issues remain in the adoption of EHRs 
and in managing data conﬁdentiality, automated processing of available 
clinical data is also a major challenge: manual identification of such 
information is time consuming and often inconsistent and incomplete. This is 
particularly the case with clinical narratives, which are often the primary, 
preferred and richest source of patient information.

The aim of this project is developing techniques for large-scale text mining 
of un- and semi-structured health textual resources, and on health-related 
information synthesis. We are currently focussed on the extraction of clinical 
events and temporal expressions and de-identification (anonymization) of 
clinical narratives. Our partner in this project is the team from the 
University of Manchester, School of Computer Science under the leadership of 
prof. Goran Nenadic.

### Software Performance Monitoring and Management

This project deals with problems of software performance management. The main 
focus of the project is the devlopment of techniques for efficient monitoring 
of working software. We want to find a way to reduce monitoring overhead. This 
can be achieved by developing adaptive monitoring tools and by using 
instrumentation that leaves smaller footprint. In collaboration with , and based 
on their [Kieker](http://kieker-monitoring.net/) monitoring tool, we have 
developed adaptive monitoring tool DProf. It automatically chooses which parts 
of software to monitor.

The second part of the project is the monitoring goal specification. For now, 
we use XML, but we are looking to develop specific language. Based on 
monitoring goals, that are defined using this language, parameters for 
monitoring systems will be generated.

The third part of this project focuses on the use of obtained monitoring data 
for performance management, prediction, capacity planning, etc.